{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jul 26 16:09:11 2017\n",
    "\n",
    "@author: cbothore\n",
    "\"\"\"\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "def naive_method(graph, empty, attr):\n",
    "    \"\"\"   Predict the missing attribute with a simple but effective\n",
    "    relational classifier. \n",
    "    \n",
    "    The assumption is that two connected nodes are \n",
    "    likely to share the same attribute value. Here we chose the most frequently\n",
    "    used attribute by the neighbors\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : graph\n",
    "       A networkx graph\n",
    "    empty : list\n",
    "       The nodes with empty attributes \n",
    "    attr : dict \n",
    "       A dict of attributes, either location, employer or college attributes. \n",
    "       key is a node, value is a list of attribute values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predicted_values : dict \n",
    "       A dict of attributes, either location, employer or college attributes. \n",
    "       key is a node (from empty), value is a list of attribute values. Here \n",
    "       only 1 value in the list.\n",
    "     \"\"\"\n",
    "    predicted_values={}\n",
    "    for n in empty:\n",
    "        nbrs_attr_values=[] \n",
    "        for nbr in graph.neighbors(n):\n",
    "            if nbr in attr:\n",
    "                for val in attr[nbr]:\n",
    "                    nbrs_attr_values.append(val)\n",
    "        predicted_values[n]=[]\n",
    "        if nbrs_attr_values: # non empty list\n",
    "            # count the number of occurrence each value and returns a dict\n",
    "            cpt=Counter(nbrs_attr_values)\n",
    "            # take the most represented attribute value among neighbors\n",
    "            a,nb_occurrence=max(cpt.items(), key=lambda t: t[1])\n",
    "            predicted_values[n].append(a)\n",
    "    return predicted_values\n",
    "    \n",
    "def evaluation_accuracy(groundtruth, pred):\n",
    "    \"\"\"    Compute the accuracy of your model.\n",
    "\n",
    "     The accuracy is the proportion of true results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    groundtruth :  : dict \n",
    "       A dict of attributes, either location, employer or college attributes. \n",
    "       key is a node, value is a list of attribute values.\n",
    "    pred : dict \n",
    "       A dict of attributes, either location, employer or college attributes. \n",
    "       key is a node, value is a list of attribute values. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : float\n",
    "       Accuracy.\n",
    "    \"\"\"\n",
    "    true_positive_prediction=0   \n",
    "    for p_key, p_value in pred.items():\n",
    "        if p_key in groundtruth:\n",
    "            # if prediction is no attribute values, e.g. [] and so is the groundtruth\n",
    "            # May happen\n",
    "            if not p_value and not groundtruth[p_key]:\n",
    "                true_positive_prediction+=1\n",
    "            # counts the number of good prediction for node p_key\n",
    "            # here len(p_value)=1 but we could have tried to predict more values\n",
    "            true_positive_prediction += len([c for c in p_value if c in groundtruth[p_key]])          \n",
    "        # no else, should not happen: train and test datasets are consistent\n",
    "    return true_positive_prediction*100/sum(len(v) for v in pred.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of users in our graph: 811\n"
     ]
    }
   ],
   "source": [
    "# load the graph\n",
    "G = nx.read_gexf(\"mediumLinkedin.gexf\")\n",
    "print(\"Nb of users in our graph: %d\" % len(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of users with one or more attribute college: 575\n",
      "Nb of users with one or more attribute location: 840\n",
      "Nb of users with one or more attribute employer: 742\n"
     ]
    }
   ],
   "source": [
    "# load the profiles. 3 files for each type of attribute\n",
    "# Some nodes in G have no attributes\n",
    "# Some nodes may have 1 attribute 'location'\n",
    "# Some nodes may have 1 or more 'colleges' or 'employers', so we\n",
    "# use dictionaries to store the attributes\n",
    "college={}\n",
    "location={}\n",
    "employer={}\n",
    "# The dictionaries are loaded as dictionaries from the disk (see pickle in Python doc)\n",
    "with open('mediumCollege_60percent_of_empty_profile.pickle', 'rb') as handle:\n",
    "    college = pickle.load(handle)\n",
    "with open('mediumLocation_60percent_of_empty_profile.pickle', 'rb') as handle:\n",
    "    location = pickle.load(handle)\n",
    "with open('mediumEmployer_60percent_of_empty_profile.pickle', 'rb') as handle:\n",
    "    employer = pickle.load(handle)\n",
    "\n",
    "print(\"Nb of users with one or more attribute college: %d\" % len(college))\n",
    "print(\"Nb of users with one or more attribute location: %d\" % len(location))\n",
    "print(\"Nb of users with one or more attribute employer: %d\" % len(employer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your mission, find attributes to 475 users with empty profile\n"
     ]
    }
   ],
   "source": [
    "# here are the empty nodes for whom your challenge is to find the profiles\n",
    "empty_nodes=[]\n",
    "with open('mediumRemovedNodes_60percent_of_empty_profile.pickle', 'rb') as handle:\n",
    "    empty_nodes = pickle.load(handle)\n",
    "print(\"Your mission, find attributes to %d users with empty profile\" % len(empty_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.947368% of the predictions are true\n",
      "Very poor result!!! Try to do better!!!!\n"
     ]
    }
   ],
   "source": [
    "# --------------------- Baseline method -------------------------------------#\n",
    "# Try a naive method to predict attribute\n",
    "# This will be a baseline method for you, i.e. you will compare your performance\n",
    "# with this method\n",
    "# Let's try with the attribute 'employer'\n",
    "employer_predictions=premier_method(G, empty_nodes, location)\n",
    "groundtruth_employer={}\n",
    "with open('largeLocation.pickle', 'rb') as handle:\n",
    "    groundtruth_employer = pickle.load(handle)\n",
    "result=evaluation_accuracy(groundtruth_employer,employer_predictions)\n",
    "print(\"%f%% of the predictions are true\" % result)\n",
    "print(\"Very poor result!!! Try to do better!!!!\")\n",
    "\n",
    "# --------------------- Now your turn -------------------------------------#\n",
    "# Explore, implement your strategy to fill empty profiles of empty_nodes\n",
    "\n",
    "\n",
    "# and compare with the ground truth (what you should have predicted)\n",
    "# user precision and recall measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_dict(graph, empty, attr):\n",
    "    mydict = {}\n",
    "    for n in empty: \n",
    "        i = 0\n",
    "        for nb in graph.neighbors(n):\n",
    "            if nb in attr:\n",
    "                i = i+1\n",
    "        mydict[n] = i\n",
    "    return mydict\n",
    "\n",
    "def get_max(mydict deja):\n",
    "    m = 0\n",
    "    for k,v in mydict.items():\n",
    "        if k not in deja:\n",
    "            if v > m: m = v\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def premier_method(graph, empty, attr):\n",
    "    \n",
    "    predicted_values = {}\n",
    "    mydict = initial_dict(graph, empty, attr)\n",
    "        \n",
    "    deja = []\n",
    "    while(len(mydict) != len(deja)):\n",
    "        mx = get_max(mydict, deja)\n",
    "        for k,v in mydict.items():\n",
    "            if k not in deja and v == mx:\n",
    "                nbrs = []\n",
    "                for nb in graph.neighbors(k):\n",
    "                    if nb in attr: nbrs.extend(attr[nb])\n",
    "                    if nb in predicted_values: nbrs.extend(predicted_values[nb])\n",
    "                    if nb in mydict: mydict[nb] = mydict[nb]+1\n",
    "                cnt = Counter(nbrs)\n",
    "                predicted_values[k] = [max(cnt, key=lambda k: cnt[k])]\n",
    "                deja.append(k)\n",
    "                \n",
    "    \"\"\"\n",
    "    # counts for how many neighbors per node the attribute is known\n",
    "    \n",
    "    \n",
    "   \n",
    "            \n",
    "                    nbrs = []\n",
    "                    for nb in graph.neighbors(k):\n",
    "                        if nb in attr:\n",
    "                            nbrs.append(attr[nb])\n",
    "                            print(nbrs)\n",
    "                    cnt = Counter(nbrs)\n",
    "                    predicted_values[k] = (max(cnt, key=lambda k: cnt[k]))\n",
    "                    print(k, predicted_values[k])\n",
    "                    attr[k] = predicted_values[k]\n",
    "                    deja.append(k)\n",
    "    \"\"\"\n",
    "    return predicted_values\n",
    "\n",
    "employer_predictions = premier_method(G, empty_nodes, location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U2691\n",
      "U24082\n"
     ]
    }
   ],
   "source": [
    "for i in G.neighbors('U24085'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'a':[1,2,3],'b':[1,2,3]}\n",
    "b = []\n",
    "b.extend(a['a'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-c68ce78b5320>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "a = {'a':0,'b':1,'c':2,'d':3,'e':5,'f':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "a\n",
    "for [k, v] in a.items():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-111-56f7e036d680>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-111-56f7e036d680>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    i++\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "i++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
